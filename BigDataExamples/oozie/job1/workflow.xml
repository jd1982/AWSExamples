<workflow-app name='example-forkjoinwf' xmlns="uri:oozie:workflow:0.1">
    <start to='firstjob' />
    <action name="firstjob">
        <map-reduce>
            <job-tracker>${nameNode}:8021</job-tracker>
            <name-node>hdfs://${nameNode}:8020</name-node>
           <configuration>
                                <property>
                                        <name>mapred.mapper.new-api</name>
                                        <value>false</value>
                                </property>
                                <property>
                                        <name>mapred.reducer.new-api</name>
                                        <value>false</value>
                                </property>
                                <property>
                                        <name>mapred.mapper.class</name>
                                        <value>com.jd.bigdata.hadoop.Map</value>
                                </property>
                                <property>
                                        <name>mapred.reducer.class</name>
                                        <value>com.jd.bigdata.hadoop.Reduce</value>
                                </property>
                                <property>
                                        <name>mapred.mapoutput.key.class</name>
                                        <value>org.apache.hadoop.io.Text</value>
                                </property>
                                <property>
                                        <name>mapred.mapoutput.value.class</name>
                                        <value>org.apache.hadoop.io.IntWritable</value>
                                </property>
                                <property>
                                        <name>mapred.output.key.class</name>
                                        <value>org.apache.hadoop.io.Text</value>
                                </property>
                                <property>
                                        <name>mapred.output.value.class</name>
                                        <value>org.apache.hadoop.io.IntWritable</value>
                                </property>
                                <property>
                                        <name>mapred.input.dir</name>
                                        <value>words/input</value>
                                </property>
                                <property>
                                        <name>mapred.output.dir</name>
                                        <value>words/output</value>
                                </property>
                                <property>
                                        <name>mapreduce.job.acl-view-job</name>
                                        <value>*</value>
                                </property>
                                <property>
                                        <name>oozie.launcher.mapreduce.job.acl-view-job</name>
                                        <value>*</value>
                                </property>
                                <property>
                                        <name>oozie.use.system.libpath</name>
                                        <value>false</value>
                                </property>
                                <property>
                                        <name>oozie.libpath</name>
                                        <value>${appPath}/lib</value>
                                </property>
                            </configuration>
        </map-reduce>
        <ok to="end" />
        <error to="kill" />
    </action>
    <kill name="kill">
        <message>Map/Reduce failed, error message[${wf:errorMessage()}]</message>
    </kill>
    <end name='end'/>
</workflow-app>

